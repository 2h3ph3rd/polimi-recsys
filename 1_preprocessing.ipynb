{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Preprocessing"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Import libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'Recommenders'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipykernel_18484/3112814805.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpretty_print_progress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_sparse_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m~/Documents/university/recsys-challenge-2022/utilities.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecommenders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecommender_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/Documents/university/recsys-challenge-2022/src/Recommenders/Recommender_src.Utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \"\"\"\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mRecommenders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSimilarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompute_Similarity_Python\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIncremental_Similarity_Builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Recommenders'"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from scipy import sparse\n",
                "import os\n",
                "import csv\n",
                "\n",
                "from utilities import pretty_print_progress, save_sparse_matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.Utils.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Read dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "base_path = \"data\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "interactions_df_path = os.path.join(base_path, \"interactions_and_impressions.csv\")\n",
                "items_length_df_path = os.path.join(base_path, \"data_ICM_length.csv\")\n",
                "items_type_df_path = os.path.join(base_path, \"data_ICM_type.csv\")\n",
                "users_df_path = os.path.join(base_path, \"data_target_users_test.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dtype = {0: int, 1: int, 2: str, 3: int}\n",
                "interactions_df = pd.read_csv(\n",
                "    filepath_or_buffer=interactions_df_path,\n",
                "    dtype=dtype,\n",
                "    keep_default_na=False  # avoid NaN\n",
                ")\n",
                "\n",
                "dtype = {0: int, 1: int, 2: int}\n",
                "items_length_df = pd.read_csv(filepath_or_buffer=items_length_df_path, dtype=dtype)\n",
                "\n",
                "items_types_df = pd.read_csv(filepath_or_buffer=items_type_df_path, dtype=dtype)\n",
                "users_df = pd.read_csv(filepath_or_buffer=users_df_path)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### IDs mapping"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "items_ids = items_types_df[\"item_id\"].unique()\n",
                "items_ids = np.append(items_ids, interactions_df[\"item_id\"].unique())\n",
                "items_ids = np.unique(items_ids)  # do also sorting\n",
                "\n",
                "users_ids = interactions_df[\"user_id\"].sort_values().unique()\n",
                "features_ids = items_types_df[\"feature_id\"].sort_values().unique()\n",
                "\n",
                "num_users = users_ids.shape[0]\n",
                "num_items = items_ids.shape[0]\n",
                "num_items_with_feature = items_ids.shape[0]\n",
                "num_items_with_interaction = interactions_df[\"item_id\"].unique().shape[0]\n",
                "num_features = features_ids.shape[0]\n",
                "num_users_to_recommend = users_df['user_id'].shape[0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 41629 users with interactions and 41116 to recommend\n",
                        "Found 27968 items, 24507 with interactions and 27968 with 5 features\n"
                    ]
                }
            ],
            "source": [
                "print(\"Found {} users with interactions and {} to recommend\".format(\n",
                "    num_users, num_users_to_recommend))\n",
                "print(\"Found {} items, {} with interactions and {} with {} features\".format(\n",
                "    num_items, num_items_with_interaction, num_items_with_feature, num_features))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "items_mapped_ids, items_original_ids = pd.factorize(items_ids)\n",
                "\n",
                "item_mapped_id_to_original_id = pd.Series(\n",
                "    items_original_ids, index=items_mapped_ids)\n",
                "item_original_id_to_mapped_id = pd.Series(\n",
                "    items_mapped_ids, index=items_original_ids)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "users_mapped_ids, users_original_ids = pd.factorize(users_ids)\n",
                "\n",
                "user_mapped_id_to_original_id = pd.Series(\n",
                "    users_original_ids, index=users_mapped_ids)\n",
                "user_original_id_to_mapped_id = pd.Series(\n",
                "    users_mapped_ids, index=users_original_ids)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "features_mapped_ids, features_original_ids = pd.factorize(features_ids)\n",
                "\n",
                "feature_mapped_id_to_original_id = pd.Series(\n",
                "    features_original_ids, index=features_mapped_ids)\n",
                "feature_original_id_to_mapped_id = pd.Series(\n",
                "    features_mapped_ids, index=features_original_ids)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Generate URM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'interactions_df' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipykernel_18484/2978289353.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteractions_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m ratings_df = df.groupby(\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ).sum(['data'])\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'interactions_df' is not defined"
                    ]
                }
            ],
            "source": [
                "df = interactions_df.copy()\n",
                "\n",
                "ratings_df = df.groupby(\n",
                "    ['user_id', 'item_id'], as_index=False\n",
                ").sum(['data'])\n",
                "\n",
                "URM = np.zeros((num_users, num_items), dtype=np.float16)\n",
                "\n",
                "for user_mapped_id in range(num_users):\n",
                "    df = ratings_df\n",
                "    user_original_id = user_mapped_id_to_original_id[user_mapped_id]\n",
                "    user_items = df[df['user_id'] == user_original_id]\n",
                "\n",
                "    for i in user_items.index:\n",
                "        item_original_id = user_items.loc[i, 'item_id']\n",
                "        item_mapped_id = item_original_id_to_mapped_id[item_original_id]\n",
                "        URM[user_mapped_id, item_mapped_id] = 1\n",
                "\n",
                "    pretty_print_progress(\n",
                "        user_mapped_id, num_users, \"Calculating URM\")\n",
                "   \n",
                "# Save matrix to external file \n",
                "save_sparse_matrix(URM, filename='urm.npz')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Generate ICM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ICM = np.zeros((num_items, num_features + 2), dtype=np.int8)\n",
                "\n",
                "for i in df.index:\n",
                "\n",
                "    item_id = df.loc[i, 'item_id']\n",
                "    feature_id = df.loc[i, 'feature_id']\n",
                "    item_id = item_original_id_to_mapped_id[item_id]\n",
                "    feature_id = feature_original_id_to_mapped_id[feature_id]\n",
                "    ICM[item_id, feature_id] = 1\n",
                "\n",
                "    pretty_print_progress(\n",
                "        i, df.shape[0], \"Calculating ICM with types\")\n",
                "\n",
                "df = items_length_df\n",
                "\n",
                "for i in df.index:\n",
                "\n",
                "    item_id = df.loc[i, 'item_id']\n",
                "    length = df.loc[i, 'data']\n",
                "    item_id = item_original_id_to_mapped_id[item_id]\n",
                "\n",
                "    if length == 0:\n",
                "        continue\n",
                "    elif length == 1:\n",
                "        feature_id = num_features\n",
                "    else:\n",
                "        feature_id = num_features + 1\n",
                "\n",
                "    ICM[item_id, feature_id] = 1\n",
                "\n",
                "    pretty_print_progress(\n",
                "        i, df.shape[0], \"Calculating ICM with items length\")\n",
                "\n",
                "save_sparse_matrix(ICM, \"./data\", \"icm.npz\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.7"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}